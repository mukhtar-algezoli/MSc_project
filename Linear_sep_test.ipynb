{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1690885598250,"user":{"displayName":"Mukhtar A.Algezoli","userId":"04463805871425779046"},"user_tz":-60},"id":"QjvVa7fZlSio"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":1792,"status":"ok","timestamp":1690885600034,"user":{"displayName":"Mukhtar A.Algezoli","userId":"04463805871425779046"},"user_tz":-60},"id":"WsYVvJzjer63"},"outputs":[],"source":["\n","\n","# imports\n","import numpy as np\n","import pandas as pd\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.decomposition import PCA\n","from matplotlib import pyplot as plt\n","from pathlib import Path\n","import os\n","import re\n","from collections import defaultdict\n","from google.colab import drive\n","from google.colab import files\n","from tqdm import tqdm"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1441,"status":"ok","timestamp":1690885601470,"user":{"displayName":"Mukhtar A.Algezoli","userId":"04463805871425779046"},"user_tz":-60},"id":"nXxbJ_lle1qv","outputId":"cde789a1-d371-4d69-8a94-d5553b7c64b7"},"outputs":[{"name":"stdout","output_type":"stream","text":["['1988', '2803', '2277', '5895', '6241', '6313', '5694', '7976', '8297', '3000', '7850', '1462', '8842', '3752', '2428', '2902', '6295', '5536', '652', '2078', '3536', '174', '2086', '1272', '1919', '6345', '3081', '3576', '777', '1673', '6319', '5338', '422', '3853', '1993', '2035', '251', '2412', '3170', '84']\n"]}],"source":["layer_num = 4\n","model = \"Hubert_collapsed_layer3\"\n","\n","\n","# get path to data\n","# directory =  \"/content/drive/MyDrive/Grad project/models_hidden_states/Wav2Vec2/dev-clean\"\n","# directory =  \"/content/drive/MyDrive/Grad project/models_hidden_states/Wav2Vec2/dev-clean\"\n","\n","# directory = \"/content/drive/MyDrive/Grad project/Oli_files/orig\"\n","directory = \"/content/drive/MyDrive/Grad project/models_hidden_states/\" + model + \"/dev-clean\"\n","# directory = \"/content/drive/MyDrive/Grad project/models_hidden_states/Hubert_outputs/Hubert_large_ASR_last_layer/Hubert_outputs/dev-clean\"\n","# alignment_file = \"/content/drive/MyDrive/Grad project/Oli_files/train-clean-100.ali\"\n","alignment_file = \"/content/drive/MyDrive/Grad project/Oli_files/dev-clean.ali\"\n","\n","\n","\n","dir_list = [x for x in next(os.walk(directory))][1]\n","\n","print(dir_list)\n","\n","# for some reason makes later function load files in correct order... create list with bash script?\n","# dir_list = [1272, 1462, 1673, 174, 1919, 1988, 1993, 2035, 2078, 2086, 2277, 2412, 2428, 251, 2803, 2902, 3000, 3081, 3170, 3536, 3576, 3752, 3853, 422, 5338, 5536, 5694, 5895, 6241, 6295, 6313, 6319, 6345, 652, 777, 7850, 7976, 8297, 84, 8842]"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1690885601470,"user":{"displayName":"Mukhtar A.Algezoli","userId":"04463805871425779046"},"user_tz":-60},"id":"_hw4WRCwthd2"},"outputs":[],"source":["apply_proj = False\n","#apply projection\n","if apply_proj:\n","  proj_mat_dir = \"/content/drive/MyDrive/Grad project/spk_phone_joint_matrices/\" + model + \"/layer_\" + str(layer_num) # path to speaker matrix\n","  speaker_arrays = np.load(proj_mat_dir + \"/speaker_matrix.npy\")\n","  pca_speaker = PCA(n_components=40)\n","  principal_components_speaker = pca_speaker.fit_transform(speaker_arrays)"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":2097,"status":"ok","timestamp":1690885603560,"user":{"displayName":"Mukhtar A.Algezoli","userId":"04463805871425779046"},"user_tz":-60},"id":"XrSdATx87ONH"},"outputs":[],"source":["with open(alignment_file, \"r\") as f:\n","  lines = [line.split() for line in f.readlines()]"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":655,"status":"ok","timestamp":1690885604211,"user":{"displayName":"Mukhtar A.Algezoli","userId":"04463805871425779046"},"user_tz":-60},"id":"kO-9pgK-V5ay"},"outputs":[],"source":["utt_allignments = {}\n","\n","\n","for line in lines[1:]:\n","  if line[0] in utt_allignments:\n","    utt_allignments[line[0]].append(line)\n","  else:\n","    utt_allignments[line[0]] = [line]\n","\n","\n"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":34,"status":"ok","timestamp":1690885604214,"user":{"displayName":"Mukhtar A.Algezoli","userId":"04463805871425779046"},"user_tz":-60},"id":"wH2fu3i47O3u"},"outputs":[],"source":["# for walking through features directory and retrieving files\n","\n","def GetFiles(path: str):\n","\n","                                                                # store files in a list\n","  files = []\n","  speaker_index = []\n","\n","  for (root, dirs, file) in os.walk(path):\n","    if re.match(f\"^{path}/\\d+$\", root):                         # group files by speaker\n","      speaker_index.append(root[len(f\"{path}/\"):])              # only append speaker id\n","      try:\n","        files.append(sorted(speaker_sublist))                   # order by utterance sample\n","      except NameError:                                         # speaker_sublist doesn't exist in the first iteration\n","        pass\n","      speaker_sublist = []\n","\n","    for f in file:                                              # append all files of specific speaker\n","      if f[-3:] == \"npy\":                                       # remove files with weird suffix after .npy\n","        speaker_sublist.append(f\"{root}/{f}\")\n","\n","  files.append(sorted(speaker_sublist))                         # to capture final speaker at the end of loop\n","\n","\n","\n","  return files, speaker_index"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":28,"status":"ok","timestamp":1690885604216,"user":{"displayName":"Mukhtar A.Algezoli","userId":"04463805871425779046"},"user_tz":-60},"id":"lDjfbgWm7cxm"},"outputs":[],"source":["def OrgFiles(dir_list: list, file_list: list, spk_list: list):\n","  spk_id_file_list = [(spk_list[i], file_list[i]) for i in range(len(spk_list))]\n","  sorted_file_list = [nested[1] for nested in sorted(spk_id_file_list)]\n","  return sorted_file_list"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":42,"status":"ok","timestamp":1690885604231,"user":{"displayName":"Mukhtar A.Algezoli","userId":"04463805871425779046"},"user_tz":-60},"id":"2YU24kMl7i5X"},"outputs":[],"source":["def RemoveDupl(file_list: list):\n","  for spk_idx,by_spk in enumerate(file_list):\n","    for array_path in by_spk:\n","      if array_path[-5] == \")\":                          # in google colab duplicates will have this pattern...\n","        file_list[spk_idx].remove(array_path)\n","  return file_list"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":49,"status":"ok","timestamp":1690885604239,"user":{"displayName":"Mukhtar A.Algezoli","userId":"04463805871425779046"},"user_tz":-60},"id":"42sRm_l87prW"},"outputs":[],"source":["def Averaging(dict_list: list):\n","\n","  avg_joint = []\n","  avg_spk = []\n","\n","  all_phones_dict = {}\n","\n","  for phones_dict in tqdm(dict_list):\n","    phones_by_speaker = []\n","    by_spk = []\n","\n","    for key in phones_dict.keys():\n","\n","      ## for joint matrix\n","      stacked = np.vstack(phones_dict[key])\n","      avg_phone_spk = np.average(stacked, axis=0)\n","      phones_by_speaker.append((key, avg_phone_spk))\n","\n","      ## for speaker matrix\n","      if key == \"SIL\" or key == \"SPN\":\n","       continue\n","      by_spk.extend(phones_dict[key])                     # add all phones into one list to average by speaker\n","\n","      ## for phone matrix\n","      if key == \"SIL\" or key == \"SPN\":\n","        continue\n","      elif key not in all_phones_dict:\n","        all_phones_dict[key] = np.vstack(phones_dict[key])\n","      else:\n","        all_phones_dict[key] = np.vstack([all_phones_dict[key], np.vstack(phones_dict[key])])\n","\n","    ## for joint matrix\n","    avg_joint.append(phones_by_speaker)\n","\n","    ## for speaker matrix\n","    stacked_spk = np.vstack([by_spk])\n","    avg_by_spk = np.average(stacked_spk, axis=0)\n","    avg_spk.append(avg_by_spk)\n","\n","  ## for phone matrix\n","  avg_phones = [(phone, np.average(all_phones_dict[phone], axis=0)) for phone in all_phones_dict]\n","\n","  return avg_phones, avg_spk, avg_joint"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":77,"status":"ok","timestamp":1690885604268,"user":{"displayName":"Mukhtar A.Algezoli","userId":"04463805871425779046"},"user_tz":-60},"id":"rnoF-R-u7-Lj"},"outputs":[],"source":["def AvgArrays(file_list: list):\n","\n","  avg_by_speaker = []\n","\n","  #utts_speaker = [np.load(utterance) for speakers in file_list for utterance in speakers]\n","  for speaker in file_list:\n","    for index,utterance in enumerate(speaker):\n","      utterance = np.load(utterance)[layer_num].squeeze()\n","      # utterance = np.load(utterance)\n","      if index == 0:\n","        utt = utterance\n","      else:\n","        utt = np.concatenate((utt, utterance))\n","\n","    avg_speaker = np.average(utt, axis = 0)\n","    avg_by_speaker.append(avg_speaker)\n","\n","  return avg_by_speaker"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":84,"status":"ok","timestamp":1690885604276,"user":{"displayName":"Mukhtar A.Algezoli","userId":"04463805871425779046"},"user_tz":-60},"id":"BnrIB-6y8C51"},"outputs":[],"source":["def StackArrs(dir_list: list, joint: list):\n","\n","  for_all = []\n","  speaker_length = []\n","\n","  for nmbr,l in enumerate(joint):\n","    bs = []                                                  # bs = \"by speaker\"\n","    for s in l:\n","      bs.append(s[0])\n","      speaker_length.append(dir_list[nmbr])\n","\n","    for_all.append(bs)\n","\n","  joint_arrays = np.vstack([s[1] for l in joint for s in l]) # grab averaged vector from tuple element in list\n","  #print(joint_arrays.shape)\n","  #print(len(for_all))\n","  #print(len(speaker_length))\n","  return joint_arrays, for_all, speaker_length"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":43674,"status":"ok","timestamp":1690885647866,"user":{"displayName":"Mukhtar A.Algezoli","userId":"04463805871425779046"},"user_tz":-60},"id":"-RW_T1B157un"},"outputs":[],"source":["# dimensions = np.arange(0, 768, dtype=int)                 # name each column in df\n","files, speaker_id = GetFiles(directory)                   # retrieve files sorted by speaker\n","sorted_files = OrgFiles(dir_list, files, speaker_id)      # put them in order of appearance of directory (to match alignment file)\n","sorted_no_dupl_files = RemoveDupl(sorted_files)"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1690885647867,"user":{"displayName":"Mukhtar A.Algezoli","userId":"04463805871425779046"},"user_tz":-60},"id":"cOu_YlG7jHNc"},"outputs":[],"source":["from collections import Counter\n","import linecache\n","import os\n","import tracemalloc\n","\n","def display_top(snapshot, key_type='lineno', limit=3):\n","    snapshot = snapshot.filter_traces((\n","        tracemalloc.Filter(False, \"\u003cfrozen importlib._bootstrap\u003e\"),\n","        tracemalloc.Filter(False, \"\u003cunknown\u003e\"),\n","    ))\n","    top_stats = snapshot.statistics(key_type)\n","\n","    print(\"Top %s lines\" % limit)\n","    for index, stat in enumerate(top_stats[:limit], 1):\n","        frame = stat.traceback[0]\n","        # replace \"/path/to/module/file.py\" with \"module/file.py\"\n","        filename = os.sep.join(frame.filename.split(os.sep)[-2:])\n","        print(\"#%s: %s:%s: %.1f KiB\"\n","              % (index, filename, frame.lineno, stat.size / 1024))\n","        line = linecache.getline(frame.filename, frame.lineno).strip()\n","        if line:\n","            print('    %s' % line)\n","\n","    other = top_stats[limit:]\n","    if other:\n","        size = sum(stat.size for stat in other)\n","        print(\"%s other: %.1f KiB\" % (len(other), size / 1024))\n","    total = sum(stat.size for stat in top_stats)\n","    print(\"Total allocated size: %.1f KiB\" % (total / 1024))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"R2b7vtFJZ8Gf"},"outputs":[{"name":"stderr","output_type":"stream","text":[" 88%|████████▊ | 35/40 [31:53\u003c05:00, 60.05s/it]"]}],"source":["\n","\n","\n","# for Hubert and all 20ms frame rate models\n","\n","# tracemalloc.start()\n","\n","list_phones_dicts = []\n","for speaker in tqdm(sorted_no_dupl_files):\n","  phones_dict = defaultdict(list)\n","\n","  for index,utterance_file_path in enumerate(speaker):\n","    # print(\"------------------------------\")\n","    # print(\"utterance:\",utterance)\n","    # print(utterance_file_path)\n","    utterance_id = utterance_file_path.split(\"/\")[-1].split(\".\")[0]\n","    # utterance = np.load(utterance_file_path, mmap_mode=\"r\")[layer_num].squeeze()\n","    utterance = np.load(utterance_file_path, mmap_mode=\"r\")[layer_num]\n","    # print(utterance.shape)\n","    # utterance = np.load(utterance_file_path, allow_pickle=True)[layer_num].squeeze()\n","\n","    # utterance = np.load(utterance_file_path, mmap_mode=\"r\")\n","    # print(utterance.shape)\n","    utt_allignment = utt_allignments[utterance_id]\n","    num_accum_frames = 0\n","    num_accum_frames_orig = 0\n","    taken_frame = []\n","    taken_frame_second = []\n","    durations = []\n","    curr_duration = 0\n","    right_start = 0\n","    wrong_start = 0\n","    num_accum_frames = 0\n","    carry = 0\n","    odd_counter = 0\n","    for id, channel, start_time, phone_duration, phone_id, phone in utt_allignment:\n","      if phone == \"SIL\":          # all phones but \"SIL\" are of type AW_I, here removing _I ending\n","        key = \"SIL\"\n","      else:                                            # slice [5] grabs the whole phone id but here sorting according to the phones in figure 2 of Oli's paper\n","        key = phone[:-2]          # get phones\n","        if key[-1].isdigit():                          # go from AW0 and AW1 to phone label AW\n","          key = key[:-1]\n","\n","\n","      # print(\"phone_duration: \",phone_duration)\n","      # print(\"number_of_frames: \",int(float(phone_duration) * 50))\n","      # number_of_frames = int(float(phone_duration) * 100) # with a frame each 10 ms\n","      number_of_frames_dec = float(phone_duration) * 50 # with a frame each 20 ms\n","      # if (number_of_frames_dec * 10) % 2 != 0:\n","      #     odd_counter = 1\n","\n","\n","      number_of_frames = int(number_of_frames_dec) + odd_counter\n","\n","      if round((number_of_frames_dec * 10) % 2, 2) != 0:\n","          odd_counter = 1\n","      else:\n","          odd_counter = 0\n","\n","      durations.append(number_of_frames)\n","      taken_frame.append(\"*# start at: \" + str(int((curr_duration * 100)/2)) + \" counter: \" + str(odd_counter) +  \" #*\")\n","      taken_frame_second.append(\"*# start at: \" + str(curr_duration) + \" counter: \" + str(odd_counter) +  \" #*\")\n","      prev_duration = int((curr_duration * 100)/2)\n","\n","      # print(round(float(phone_duration), 2))\n","\n","      curr_duration += round(float(phone_duration), 2)\n","      number_of_frames = int((curr_duration * 100)/2) - prev_duration\n","      # print(round(float(phone_duration), 2) * 100)\n","\n","\n","\n","\n","\n","      # if number_of_frames_dec.is_integer():\n","      #   carry = 0\n","      # else:\n","      #   carry = 1\n","\n","\n","\n","      for frame in range(number_of_frames):\n","          try:\n","            if apply_proj:\n","              z = utterance[num_accum_frames + frame]\n","              for pca in pca_speaker.components_:\n","                # z = z - (np.transpose(z) * pca) * pca\n","                z = np.subtract(z, np.multiply(np.matmul(z, pca), pca))\n","            else:\n","              z = utterance[num_accum_frames + frame]\n","            phones_dict[key].append(z)\n","          except IndexError:\n","            print(\"length of utterance: \",utterance.shape[0])\n","            print(\"appended frame index:\",num_accum_frames + frame)\n","\n","      # num_accum_frames += number_of_frames + odd_counter\n","      num_accum_frames += number_of_frames\n","\n","\n","    # del utterance.f\n","    # utterance.close()\n","    # print(taken_frame)\n","    # print(taken_frame_second)\n","    # print(durations)\n","    # print(num_accum_frames)\n","\n","  list_phones_dicts.append(phones_dict)\n","  # break\n","\n","  # snapshot = tracemalloc.take_snapshot()\n","  # display_top(snapshot)\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oAZ01pQN53Xf"},"outputs":[],"source":["# # tracemalloc.start()\n","\n","# list_phones_dicts = []\n","# for speaker in tqdm(sorted_no_dupl_files):\n","#   phones_dict = defaultdict(list)\n","\n","#   for index,utterance_file_path in enumerate(speaker):\n","#     # print(\"------------------------------\")\n","#     # print(\"utterance:\",utterance)\n","#     utterance_id = utterance_file_path.split(\"/\")[-1].split(\".\")[0]\n","#     utterance = np.load(utterance_file_path, mmap_mode=\"r\")[layer_num].squeeze()\n","#     # utterance = np.load(utterance_file_path, mmap_mode=\"r\")\n","\n","#     # utterance_new = utterance.tolist()\n","#     # print(utterance.shape)\n","#     utt_allignment = utt_allignments[utterance_id]\n","#     # print(\"num frames:\",utterance.shape)\n","#     # print(utt_allignment)\n","#     # print(\"allignments duration:\",float(utt_allignment[-1][2]) + float(utt_allignment[-1][3]))\n","#     num_accum_frames = 0\n","#     carry = 0\n","#     for id, channel, start_time, phone_duration, phone_id, phone in utt_allignment:\n","#       if phone == \"SIL\":          # all phones but \"SIL\" are of type AW_I, here removing _I ending\n","#         key = \"SIL\"\n","#       else:                                            # slice [5] grabs the whole phone id but here sorting according to the phones in figure 2 of Oli's paper\n","#         key = phone[:-2]          # get phones\n","#         if key[-1].isdigit():                          # go from AW0 and AW1 to phone label AW\n","#           key = key[:-1]\n","\n","\n","#       # print(\"phone_duration: \",phone_duration)\n","#       # print(\"number_of_frames: \",int(float(phone_duration) * 50))\n","#       number_of_frames = int(float(phone_duration) * 100) # with a frame each 10 ms\n","#       # number_of_frames_dec = float(phone_duration) * 50 # with a frame each 20 ms\n","\n","\n","#       # number_of_frames = int(number_of_frames_dec)\n","\n","\n","\n","#       # if number_of_frames_dec.is_integer():\n","#       #   carry = 0\n","#       # else:\n","#       #   carry = 1\n","\n","\n","#       for frame in range(number_of_frames):\n","#           try:\n","#             if apply_proj:\n","#               z = utterance[num_accum_frames + frame]\n","#               for pca in pca_speaker.components_:\n","#                 # z = z - (np.transpose(z) * pca) * pca\n","#                 z = np.subtract(z, np.multiply(np.matmul(z, pca), pca))\n","#             else:\n","#               z = utterance[num_accum_frames + frame]\n","#             phones_dict[key].append(z)\n","#           except IndexError:\n","#             print(\"length of utterance: \",utterance.shape[0])\n","#             print(\"appended frame index:\",num_accum_frames + frame)\n","\n","#       num_accum_frames += number_of_frames\n","\n","\n","#     # del utterance.f\n","#     # utterance.close()\n","\n","#   list_phones_dicts.append(phones_dict)\n","#   # break\n","\n","#   # snapshot = tracemalloc.take_snapshot()\n","#   # display_top(snapshot)\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nvoPGaXONPtQ"},"outputs":[],"source":["# phones_dataset = []"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xdn3UKj3Nir4"},"outputs":[],"source":["# for speaker_dict in list_phones_dicts:\n","#   for key, val in speaker_dict.items():\n","#     tmp = {\"phone\":key, \"rep\":val}\n","#     phones_dataset.append(tmp)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c1sE0JzAN0sc"},"outputs":[],"source":["# df = pd.DataFrame(phones_dataset)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CvnU8kM_N7p2"},"outputs":[],"source":["# df.to_csv(\"phones.csv\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LYOnCPDj9-9k"},"outputs":[],"source":["speaker_ids = []\n","for speaker in sorted_no_dupl_files:\n","  speaker_ids.append(speaker[0].split(\"/\")[8])\n","\n","phones_dict = {value:[] for value in list_phones_dicts[0].keys()}\n","\n","speakers_dict = {value:[] for value in speaker_ids}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QxxXoKETAW0o"},"outputs":[],"source":["for index, speaker_dict in enumerate(list_phones_dicts):\n","  speaker_id = sorted_no_dupl_files[index][0].split(\"/\")[8]\n","  for key, val in tqdm(speaker_dict.items()):\n","    speakers_dict[speaker_id].extend(val)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lnb4eF-BQaoF"},"outputs":[],"source":["for speaker_dict_val in list_phones_dicts:\n","  for key, val in speaker_dict_val.items():\n","    phones_dict[key].extend(val)\n"]},{"cell_type":"markdown","metadata":{"id":"echVU9Gqvnrb"},"source":["# speaker classification"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nDVcdrekREmk"},"outputs":[],"source":["X_speaker, Y_speaker = [], []\n","for key, val in speakers_dict.items():\n","  for rep in val:\n","    X_speaker.append(rep)\n","    Y_speaker.append(key)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"alHDZO26PZ45"},"outputs":[],"source":["import sklearn as sk\n","import numpy as np\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3yp-7O2fPa5Z"},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","\n","# Get dataset with only the first two attributes\n","X, y = X_speaker, Y_speaker\n","# Split the dataset into a training and a testing set\n","# Test set will be the 25% taken randomly\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.50, random_state=33)\n","# print (X_train.shape, y_train.shape)\n","# # Standarize the features\n","# # Feature Scaling\n","# #For each feature, calculate the average, subtract the mean\n","# #value from the feature value, and divide the result by their standard deviation. After\n","# #scaling, each feature will have a zero average, with a standard deviation of one.\n","# scaler = StandardScaler().fit(X_train)\n","# X_train = scaler.transform(X_train)\n","\n","# X_test = scaler.transform(X_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HvoWpig4No2g"},"outputs":[],"source":["from sklearn.linear_model import LogisticRegression\n","logisticRegr = LogisticRegression(verbose=1)\n","logisticRegr.fit(X_train, y_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RALhkWCiNo6Q"},"outputs":[],"source":["from sklearn import metrics\n","y_train_pred = logisticRegr.predict(X_train)\n","print (metrics.accuracy_score(y_train, y_train_pred))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ARwNZN5yODY5"},"outputs":[],"source":["from sklearn import metrics\n","#Measure accuracy on the testing set\n","y_pred = logisticRegr.predict(X_test)\n","print (metrics.accuracy_score(y_test, y_pred))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2PMy7uVeYVo0"},"outputs":[],"source":["print(1 - metrics.accuracy_score(y_test, y_pred))"]},{"cell_type":"markdown","metadata":{"id":"cAtxWW8vvv-I"},"source":["# phone classifcation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DwrjOUMav3Zj"},"outputs":[],"source":["X_phone, Y_phone = [], []\n","for key, val in phones_dict.items():\n","  for rep in val:\n","    X_phone.append(rep)\n","    Y_phone.append(key)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JwQAmBrLv3Zo"},"outputs":[],"source":["import sklearn as sk\n","import numpy as np\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_76DBnf6v3Zo"},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","\n","# Get dataset with only the first two attributes\n","X, y = X_phone, Y_phone\n","# Split the dataset into a training and a testing set\n","# Test set will be the 25% taken randomly\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.50, random_state=33)\n","# print (X_train.shape, y_train.shape)\n","# # Standarize the features\n","# # Feature Scaling\n","# #For each feature, calculate the average, subtract the mean\n","# #value from the feature value, and divide the result by their standard deviation. After\n","# #scaling, each feature will have a zero average, with a standard deviation of one.\n","# scaler = StandardScaler().fit(X_train)\n","# X_train = scaler.transform(X_train)\n","\n","# X_test = scaler.transform(X_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eDN2o5afv3Zo"},"outputs":[],"source":["from sklearn.linear_model import LogisticRegression\n","logisticRegr = LogisticRegression(verbose=1)\n","logisticRegr.fit(X_train, y_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ovVwIhKIv3Zo"},"outputs":[],"source":["from sklearn import metrics\n","y_train_pred = logisticRegr.predict(X_train)\n","print (metrics.accuracy_score(y_train, y_train_pred))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KWLvsvH-v3Zo"},"outputs":[],"source":["from sklearn import metrics\n","#Measure accuracy on the testing set\n","y_pred = logisticRegr.predict(X_test)\n","print (metrics.accuracy_score(y_test, y_pred))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yYnTYsGWOP-A"},"outputs":[],"source":["print(1 - metrics.accuracy_score(y_test, y_pred))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rLQvSdiYOQAx"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"obp16DOdOQDV"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VHjC9FxjOQF3"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p4DorETVOQIy"},"outputs":[],"source":[]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPezKf9wu3BRKBCLR01C67m","mount_file_id":"119HyYqLHD3gNQjMjE6n7Df2XfLdP2qir","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}