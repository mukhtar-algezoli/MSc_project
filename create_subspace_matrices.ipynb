{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":3145,"status":"ok","timestamp":1691406169364,"user":{"displayName":"Mukhtar A.Algezoli","userId":"04463805871425779046"},"user_tz":-60},"id":"WsYVvJzjer63"},"outputs":[],"source":["\n","\n","# imports\n","import numpy as np\n","import pandas as pd\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.decomposition import PCA\n","from matplotlib import pyplot as plt\n","from pathlib import Path\n","import os\n","import re\n","from collections import defaultdict\n","from google.colab import drive\n","from google.colab import files\n","from tqdm import tqdm"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":529,"status":"ok","timestamp":1691406169892,"user":{"displayName":"Mukhtar A.Algezoli","userId":"04463805871425779046"},"user_tz":-60},"id":"nXxbJ_lle1qv","outputId":"994d16f1-56ae-4e47-cc2a-5df4f3a3d3f8"},"outputs":[{"output_type":"stream","name":"stdout","text":["['1988', '2803', '2277', '5895', '6241', '6313', '5694', '7976', '8297', '3000', '7850', '1462', '8842', '3752', '2428', '2902', '6295', '5536', '652', '2078', '3536', '174', '2086', '1272', '1919', '6345', '3081', '3576', '777', '1673', '6319', '5338', '422', '3853', '1993', '2035', '251', '2412', '3170', '84']\n"]}],"source":["layer_num =11\n","model = \"Hubert_SID\"\n","\n","# get path to data\n","# directory =  \"/content/drive/MyDrive/Grad project/models_hidden_states/Wav2Vec2/dev-clean\"\n","# directory =  \"/content/drive/MyDrive/Grad project/models_hidden_states/Wav2Vec2/dev-clean\"\n","directory = \"/content/drive/MyDrive/Grad project/models_hidden_states/\" + model + \"/dev-clean\"\n","\n","# directory = \"/content/drive/MyDrive/Grad project/Oli_files/orig\"\n","# directory = \"/content/drive/MyDrive/Grad project/models_hidden_states/Hubert_outputs/Hubert_large_ASR_last_layer/Hubert_outputs/dev-clean\"\n","# alignment_file = \"/content/drive/MyDrive/Grad project/Oli_files/train-clean-100.ali\"\n","alignment_file = \"/content/drive/MyDrive/Grad project/Oli_files/dev-clean.ali\"\n","\n","\n","\n","dir_list = [x for x in next(os.walk(directory))][1]\n","\n","print(dir_list)\n","\n","# for some reason makes later function load files in correct order... create list with bash script?\n","# dir_list = [1272, 1462, 1673, 174, 1919, 1988, 1993, 2035, 2078, 2086, 2277, 2412, 2428, 251, 2803, 2902, 3000, 3081, 3170, 3536, 3576, 3752, 3853, 422, 5338, 5536, 5694, 5895, 6241, 6295, 6313, 6319, 6345, 652, 777, 7850, 7976, 8297, 84, 8842]"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":2082,"status":"ok","timestamp":1691406172266,"user":{"displayName":"Mukhtar A.Algezoli","userId":"04463805871425779046"},"user_tz":-60},"id":"XrSdATx87ONH"},"outputs":[],"source":["with open(alignment_file, \"r\") as f:\n","  lines = [line.split() for line in f.readlines()]"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":366,"status":"ok","timestamp":1691406172631,"user":{"displayName":"Mukhtar A.Algezoli","userId":"04463805871425779046"},"user_tz":-60},"id":"kO-9pgK-V5ay"},"outputs":[],"source":["utt_allignments = {}\n","\n","\n","for line in lines[1:]:\n","  if line[0] in utt_allignments:\n","    utt_allignments[line[0]].append(line)\n","  else:\n","    utt_allignments[line[0]] = [line]\n","\n","\n"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1691406172631,"user":{"displayName":"Mukhtar A.Algezoli","userId":"04463805871425779046"},"user_tz":-60},"id":"wH2fu3i47O3u"},"outputs":[],"source":["# for walking through features directory and retrieving files\n","\n","def GetFiles(path: str):\n","\n","                                                                # store files in a list\n","  files = []\n","  speaker_index = []\n","\n","  for (root, dirs, file) in os.walk(path):\n","    if re.match(f\"^{path}/\\d+$\", root):                         # group files by speaker\n","      speaker_index.append(root[len(f\"{path}/\"):])              # only append speaker id\n","      try:\n","        files.append(sorted(speaker_sublist))                   # order by utterance sample\n","      except NameError:                                         # speaker_sublist doesn't exist in the first iteration\n","        pass\n","      speaker_sublist = []\n","\n","    for f in file:                                              # append all files of specific speaker\n","      if f[-3:] == \"npy\":                                       # remove files with weird suffix after .npy\n","        speaker_sublist.append(f\"{root}/{f}\")\n","\n","  files.append(sorted(speaker_sublist))                         # to capture final speaker at the end of loop\n","\n","\n","\n","  return files, speaker_index"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":321,"status":"ok","timestamp":1691406172951,"user":{"displayName":"Mukhtar A.Algezoli","userId":"04463805871425779046"},"user_tz":-60},"id":"lDjfbgWm7cxm"},"outputs":[],"source":["def OrgFiles(dir_list: list, file_list: list, spk_list: list):\n","  spk_id_file_list = [(spk_list[i], file_list[i]) for i in range(len(spk_list))]\n","  sorted_file_list = [nested[1] for nested in sorted(spk_id_file_list)]\n","  return sorted_file_list"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1691406172951,"user":{"displayName":"Mukhtar A.Algezoli","userId":"04463805871425779046"},"user_tz":-60},"id":"2YU24kMl7i5X"},"outputs":[],"source":["def RemoveDupl(file_list: list):\n","  for spk_idx,by_spk in enumerate(file_list):\n","    for array_path in by_spk:\n","      if array_path[-5] == \")\":                          # in google colab duplicates will have this pattern...\n","        file_list[spk_idx].remove(array_path)\n","  return file_list"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1691406172951,"user":{"displayName":"Mukhtar A.Algezoli","userId":"04463805871425779046"},"user_tz":-60},"id":"42sRm_l87prW"},"outputs":[],"source":["def Averaging(dict_list: list):\n","\n","  avg_joint = []\n","  avg_spk = []\n","\n","  all_phones_dict = {}\n","\n","  for phones_dict in tqdm(dict_list):\n","    phones_by_speaker = []\n","    by_spk = []\n","\n","    for key in phones_dict.keys():\n","\n","      ## for joint matrix\n","      stacked = np.vstack(phones_dict[key])\n","      avg_phone_spk = np.average(stacked, axis=0)\n","      phones_by_speaker.append((key, avg_phone_spk))\n","\n","      ## for speaker matrix\n","      if key == \"SIL\" or key == \"SPN\":\n","       continue\n","      by_spk.extend(phones_dict[key])                     # add all phones into one list to average by speaker\n","\n","      ## for phone matrix\n","      if key == \"SIL\" or key == \"SPN\":\n","        continue\n","      elif key not in all_phones_dict:\n","        all_phones_dict[key] = np.vstack(phones_dict[key])\n","      else:\n","        all_phones_dict[key] = np.vstack([all_phones_dict[key], np.vstack(phones_dict[key])])\n","\n","    ## for joint matrix\n","    avg_joint.append(phones_by_speaker)\n","\n","    ## for speaker matrix\n","    stacked_spk = np.vstack([by_spk])\n","    avg_by_spk = np.average(stacked_spk, axis=0)\n","    avg_spk.append(avg_by_spk)\n","\n","  ## for phone matrix\n","  avg_phones = [(phone, np.average(all_phones_dict[phone], axis=0)) for phone in all_phones_dict]\n","\n","  return avg_phones, avg_spk, avg_joint"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1691406172951,"user":{"displayName":"Mukhtar A.Algezoli","userId":"04463805871425779046"},"user_tz":-60},"id":"rnoF-R-u7-Lj"},"outputs":[],"source":["def AvgArrays(file_list: list):\n","\n","  avg_by_speaker = []\n","\n","  #utts_speaker = [np.load(utterance) for speakers in file_list for utterance in speakers]\n","  for speaker in file_list:\n","    for index,utterance in enumerate(speaker):\n","      utterance = np.load(utterance)[layer_num].squeeze()\n","      # utterance = np.load(utterance)\n","      if index == 0:\n","        utt = utterance\n","      else:\n","        utt = np.concatenate((utt, utterance))\n","\n","    avg_speaker = np.average(utt, axis = 0)\n","    avg_by_speaker.append(avg_speaker)\n","\n","  return avg_by_speaker"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1691406172951,"user":{"displayName":"Mukhtar A.Algezoli","userId":"04463805871425779046"},"user_tz":-60},"id":"BnrIB-6y8C51"},"outputs":[],"source":["def StackArrs(dir_list: list, joint: list):\n","\n","  for_all = []\n","  speaker_length = []\n","\n","  for nmbr,l in enumerate(joint):\n","    bs = []                                                  # bs = \"by speaker\"\n","    for s in l:\n","      bs.append(s[0])\n","      speaker_length.append(dir_list[nmbr])\n","\n","    for_all.append(bs)\n","\n","  joint_arrays = np.vstack([s[1] for l in joint for s in l]) # grab averaged vector from tuple element in list\n","  #print(joint_arrays.shape)\n","  #print(len(for_all))\n","  #print(len(speaker_length))\n","  return joint_arrays, for_all, speaker_length"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1691406172951,"user":{"displayName":"Mukhtar A.Algezoli","userId":"04463805871425779046"},"user_tz":-60},"id":"Cx_ZHuRp7lAy"},"outputs":[],"source":["# def LoadByAlign(file_list: list, alignments: list):\n","\n","#   list_phones_dicts = []\n","#   count_lines = 1                                        # leave out first row as this is the header\n","\n","#   for speaker in tqdm(file_list):\n","#     phones_dict = defaultdict(list)\n","\n","#     for index,utterance in enumerate(speaker):\n","#       #print(utterance)\n","#       utterance = np.load(utterance)[layer_num].squeeze()\n","#       same_utt = utterance.shape[0]\n","#       #print(\"utterance.shape[0] for utt nmbr:\", index, utterance.shape[0])\n","\n","#       # ['utt_id', 'channel_num', 'start_time', 'phone_dur', 'phone_id', 'phone']\n","#       while same_utt > 0:\n","#         #### REMOVE SIL AND SPN!!\n","#         if alignments[count_lines][5] == \"SIL\":          # all phones but \"SIL\" are of type AW_I, here removing _I ending\n","#           key = \"SIL\"\n","#         else:                                            # slice [5] grabs the whole phone id but here sorting according to the phones in figure 2 of Oli's paper\n","#           key = alignments[count_lines][5][:-2]          # get phones\n","#           if key[-1].isdigit():                          # go from AW0 and AW1 to phone label AW\n","#             key = key[:-1]\n","\n","#         #number_of_frames = int(round(float(alignments[count_lines][3]) * 100))   # grab floating and multiply because the frames are extracted every ten ms.\n","#         number_of_frames = int(alignments[count_lines][3][0] + alignments[count_lines][3][2:-1]) #### are you catching 12.5?\n","#         #print(\"nmbr_frames\", number_of_frames)\n","#         diff = utterance.shape[0] - same_utt -2                                   # subtract one from utt.shape[0] and another because of zero indexing, eg if we subtracted 51 frames in the previous iteration we count that as diff=50 because 0-50=51.                           # counts previous frames\n","#         #print(\"diff\", diff)\n","\n","#         # print(\"================\", utterance.shape[0])\n","#         # print(\"////////////////\",alignments[count_lines][3][0])\n","#         # print(\"------------------\",alignments[count_lines][3][2:-1])\n","#         # print(\")))))))))))))))))))\", number_of_frames)\n","\n","#         for frames in range(number_of_frames):\n","#           try:\n","#           # print(diff + frames)\n","#           # print(utterance[diff + frames])\n","#             phones_dict[key].append(utterance[diff + frames])\n","#           except IndexError:\n","#             print(\"///////////////\",utterance.shape[0])\n","#             print(\"===============\",diff + frames)\n","\n","#         same_utt -= number_of_frames\n","#         count_lines += 1\n","#         #print(\"same_utt\", same_utt)\n","\n","#         if same_utt == 1:                              # because of mismatch but what about edge cases of small durations?? And what about this assumption of alignment to silence?\n","#           phones_dict[key].append(utterance[-1])\n","#           same_utt = 0\n","#         #elif same_utt == 2:                            #### REMOVE??\n","#         #  phones_dict[key].append(utterance[-2])\n","#         #  phones_dict[key].append(utterance[-1])\n","#         #  same_utt = 0\n","#         #  print(\"key\", key, \"same_utt\", same_utt)\n","\n","#     list_phones_dicts.append(phones_dict)\n","\n","#   return list_phones_dicts"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":29740,"status":"ok","timestamp":1691406202689,"user":{"displayName":"Mukhtar A.Algezoli","userId":"04463805871425779046"},"user_tz":-60},"id":"-RW_T1B157un"},"outputs":[],"source":["# dimensions = np.arange(0, 768, dtype=int)                 # name each column in df\n","files, speaker_id = GetFiles(directory)                   # retrieve files sorted by speaker\n","sorted_files = OrgFiles(dir_list, files, speaker_id)      # put them in order of appearance of directory (to match alignment file)\n","sorted_no_dupl_files = RemoveDupl(sorted_files)"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1691406202689,"user":{"displayName":"Mukhtar A.Algezoli","userId":"04463805871425779046"},"user_tz":-60},"id":"cOu_YlG7jHNc"},"outputs":[],"source":["# from collections import Counter\n","# import linecache\n","# import os\n","# import tracemalloc\n","\n","# def display_top(snapshot, key_type='lineno', limit=3):\n","#     snapshot = snapshot.filter_traces((\n","#         tracemalloc.Filter(False, \"<frozen importlib._bootstrap>\"),\n","#         tracemalloc.Filter(False, \"<unknown>\"),\n","#     ))\n","#     top_stats = snapshot.statistics(key_type)\n","\n","#     print(\"Top %s lines\" % limit)\n","#     for index, stat in enumerate(top_stats[:limit], 1):\n","#         frame = stat.traceback[0]\n","#         # replace \"/path/to/module/file.py\" with \"module/file.py\"\n","#         filename = os.sep.join(frame.filename.split(os.sep)[-2:])\n","#         print(\"#%s: %s:%s: %.1f KiB\"\n","#               % (index, filename, frame.lineno, stat.size / 1024))\n","#         line = linecache.getline(frame.filename, frame.lineno).strip()\n","#         if line:\n","#             print('    %s' % line)\n","\n","#     other = top_stats[limit:]\n","#     if other:\n","#         size = sum(stat.size for stat in other)\n","#         print(\"%s other: %.1f KiB\" % (len(other), size / 1024))\n","#     total = sum(stat.size for stat in top_stats)\n","#     print(\"Total allocated size: %.1f KiB\" % (total / 1024))"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1691406202689,"user":{"displayName":"Mukhtar A.Algezoli","userId":"04463805871425779046"},"user_tz":-60},"id":"oAZ01pQN53Xf"},"outputs":[],"source":["# for 10 ms models but with 20ms rate\n","\n","# # tracemalloc.start()\n","\n","# list_phones_dicts = []\n","# for speaker in tqdm(sorted_no_dupl_files):\n","#   phones_dict = defaultdict(list)\n","\n","#   for index,utterance_file_path in enumerate(speaker):\n","#     # print(\"------------------------------\")\n","#     # print(\"utterance:\",utterance)\n","#     utterance_id = utterance_file_path.split(\"/\")[-1].split(\".\")[0]\n","#     # utterance = np.load(utterance_file_path, mmap_mode=\"r\")[layer_num].squeeze()\n","#     utterance = np.load(utterance_file_path, mmap_mode=\"r\")\n","#     # print(utterance.shape)\n","#     utt_allignment = utt_allignments[utterance_id]\n","#     # print(\"num frames:\",utterance.shape)\n","#     # print(utt_allignment)\n","#     # print(\"allignments duration:\",float(utt_allignment[-1][2]) + float(utt_allignment[-1][3]))\n","#     num_accum_frames = 0\n","#     carry = 0\n","#     for id, channel, start_time, phone_duration, phone_id, phone in utt_allignment:\n","#       odd_counter = 0\n","#       if phone == \"SIL\":          # all phones but \"SIL\" are of type AW_I, here removing _I ending\n","#         key = \"SIL\"\n","#       else:                                            # slice [5] grabs the whole phone id but here sorting according to the phones in figure 2 of Oli's paper\n","#         key = phone[:-2]          # get phones\n","#         if key[-1].isdigit():                          # go from AW0 and AW1 to phone label AW\n","#           key = key[:-1]\n","\n","\n","#       # print(\"phone_duration: \",phone_duration)\n","#       # print(\"number_of_frames: \",int(float(phone_duration) * 50))\n","#       # number_of_frames = int(float(phone_duration) * 100) # with a frame each 10 ms\n","#       number_of_frames_dec = float(phone_duration) * 50 # with a frame each 20 ms\n","#       # if (number_of_frames_dec * 10) % 2 != 0:\n","#       #     odd_counter = 1\n","#       if round((number_of_frames_dec * 10) % 2, 2) != 0:\n","#           odd_counter += 1\n","\n","#       number_of_frames = int(number_of_frames_dec)\n","\n","\n","\n","#       # if number_of_frames_dec.is_integer():\n","#       #   carry = 0\n","#       # else:\n","#       #   carry = 1\n","\n","\n","#       for frame in range(number_of_frames):\n","#           try:\n","#             phones_dict[key].append(utterance[num_accum_frames + frame * 2])\n","#           except IndexError:\n","#             print(\"length of utterance: \",utterance.shape[0])\n","#             print(\"appended frame index:\",num_accum_frames + frame * 2)\n","\n","#       num_accum_frames += number_of_frames * 2 + odd_counter\n","\n","\n","#     # del utterance.f\n","#     # utterance.close()\n","\n","#   list_phones_dicts.append(phones_dict)\n","\n","#   # snapshot = tracemalloc.take_snapshot()\n","#   # display_top(snapshot)\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WRG9W2Foj5_4","outputId":"277dd5e8-be8f-4252-8611-3775001442a4"},"outputs":[{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":[" 50%|█████     | 20/40 [06:38<06:37, 19.90s/it]"]}],"source":["# for Hubert and all 20ms frame rate models\n","\n","# tracemalloc.start()\n","\n","list_phones_dicts = []\n","for speaker in tqdm(sorted_no_dupl_files):\n","  phones_dict = defaultdict(list)\n","\n","  for index,utterance_file_path in enumerate(speaker):\n","    # print(\"------------------------------\")\n","    # print(\"utterance:\",utterance)\n","    # print(utterance_file_path)\n","    utterance_id = utterance_file_path.split(\"/\")[-1].split(\".\")[0]\n","    utterance = np.load(utterance_file_path, mmap_mode=\"r\")[layer_num].squeeze()\n","    # utterance = np.load(utterance_file_path, mmap_mode=\"r\")\n","    # print(utterance.shape)\n","    utt_allignment = utt_allignments[utterance_id]\n","    num_accum_frames = 0\n","    num_accum_frames_orig = 0\n","    taken_frame = []\n","    taken_frame_second = []\n","    durations = []\n","    curr_duration = 0\n","    right_start = 0\n","    wrong_start = 0\n","    num_accum_frames = 0\n","    carry = 0\n","    odd_counter = 0\n","    for id, channel, start_time, phone_duration, phone_id, phone in utt_allignment:\n","      if phone == \"SIL\":          # all phones but \"SIL\" are of type AW_I, here removing _I ending\n","        key = \"SIL\"\n","      else:                                            # slice [5] grabs the whole phone id but here sorting according to the phones in figure 2 of Oli's paper\n","        key = phone[:-2]          # get phones\n","        if key[-1].isdigit():                          # go from AW0 and AW1 to phone label AW\n","          key = key[:-1]\n","\n","\n","      # print(\"phone_duration: \",phone_duration)\n","      # print(\"number_of_frames: \",int(float(phone_duration) * 50))\n","      # number_of_frames = int(float(phone_duration) * 100) # with a frame each 10 ms\n","      number_of_frames_dec = float(phone_duration) * 50 # with a frame each 20 ms\n","      # if (number_of_frames_dec * 10) % 2 != 0:\n","      #     odd_counter = 1\n","\n","\n","      number_of_frames = int(number_of_frames_dec) + odd_counter\n","\n","      if round((number_of_frames_dec * 10) % 2, 2) != 0:\n","          odd_counter = 1\n","      else:\n","          odd_counter = 0\n","\n","      durations.append(number_of_frames)\n","      taken_frame.append(\"*# start at: \" + str(int((curr_duration * 100)/2)) + \" counter: \" + str(odd_counter) +  \" #*\")\n","      taken_frame_second.append(\"*# start at: \" + str(curr_duration) + \" counter: \" + str(odd_counter) +  \" #*\")\n","      prev_duration = int((curr_duration * 100)/2)\n","\n","      # print(round(float(phone_duration), 2))\n","\n","      curr_duration += round(float(phone_duration), 2)\n","      number_of_frames = int((curr_duration * 100)/2) - prev_duration\n","      # print(round(float(phone_duration), 2) * 100)\n","\n","\n","\n","\n","\n","      # if number_of_frames_dec.is_integer():\n","      #   carry = 0\n","      # else:\n","      #   carry = 1\n","\n","\n","\n","      for frame in range(number_of_frames):\n","          try:\n","            phones_dict[key].append(utterance[num_accum_frames + frame])\n","            taken_frame.append(num_accum_frames + frame)\n","            taken_frame_second.append(num_accum_frames + frame)\n","          except IndexError:\n","            print(\"length of utterance: \",utterance.shape[0])\n","            print(\"appended frame index:\",num_accum_frames + frame)\n","\n","      # num_accum_frames += number_of_frames + odd_counter\n","      num_accum_frames += number_of_frames\n","\n","\n","    # del utterance.f\n","    # utterance.close()\n","    # print(taken_frame)\n","    # print(taken_frame_second)\n","    # print(durations)\n","    # print(num_accum_frames)\n","\n","  list_phones_dicts.append(phones_dict)\n","  # break\n","\n","  # snapshot = tracemalloc.take_snapshot()\n","  # display_top(snapshot)\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l0TCHQT6zxFk"},"outputs":[],"source":["# debugging\n","\n","# # tracemalloc.start()\n","\n","# list_phones_dicts = []\n","# right_start = 0\n","# wrong_start = 0\n","# for speaker in tqdm(sorted_no_dupl_files):\n","#   phones_dict = defaultdict(list)\n","#   for index,utterance_file_path in enumerate(speaker):\n","#     # print(utterance_file_path)\n","#     utterance_id = utterance_file_path.split(\"/\")[-1].split(\".\")[0]\n","#     utterance = np.load(utterance_file_path, mmap_mode=\"r\")\n","#     utterance_length = utterance.shape[0]\n","#     # print(utterance_length)\n","#     utt_allignment = utt_allignments[utterance_id]\n","#     num_accum_frames = 0\n","#     num_accum_frames_orig = 0\n","#     taken_frame = []\n","#     taken_frame_orig = []\n","#     durations = []\n","#     curr_duration = 0\n","#     right_start = 0\n","#     wrong_start = 0\n","#     for id, channel, start_time, phone_duration, phone_id, phone in utt_allignment:\n","#         counter = 0\n","#         if phone == \"SIL\":          # all phones but \"SIL\" are of type AW_I, here removing _I ending\n","#           key = \"SIL\"\n","#         else:                                            # slice [5] grabs the whole phone id but here sorting according to the phones in figure 2 of Oli's paper\n","#           key = phone[:-2]          # get phones\n","#           if key[-1].isdigit():                          # go from AW0 and AW1 to phone label AW\n","#             key = key[:-1]\n","#         durations.append(\"*\")\n","#         # number_of_frames = int(float(phone_duration) * 100) # with a frame each 10 ms\n","#         orig_num_frames = int(float(phone_duration) * 100)\n","\n","#         number_of_frames_dec = round(float(phone_duration), 2) * 50 # with a frame each 20 ms\n","#         if round((number_of_frames_dec * 10) % 2, 2) != 0:\n","#           # print(round((number_of_frames_dec * 10) % 2, 2))\n","#           counter += 1\n","\n","#         number_of_frames = int(number_of_frames_dec)\n","\n","#         durations.append(number_of_frames)\n","#         taken_frame.append(\"*# start at: \" + str(curr_duration) + \" counter: \" + str(counter) +  \" #*\")\n","#         curr_duration += round(float(phone_duration), 2)\n","#         taken_frame_orig.append(\"*\")\n","#         start = True\n","#         for frame in range(number_of_frames):\n","#             # if start:\n","#             #   if round(curr_duration - round(float(phone_duration), 2), 2) * 100 == round(num_accum_frames + frame * 2, 2):\n","#             #     right_start += 1\n","#             #     print(\"righ start ##########\")\n","#             #   else:\n","#             #     print((curr_duration - round(float(phone_duration), 2)))\n","#             #     print(num_accum_frames + frame * 2)\n","#             #     wrong_start += 1\n","#             #     print(\"wrong start !!!!!!!!\")\n","#             try:\n","#               phones_dict[key].append(utterance[num_accum_frames + frame * 2])\n","#               taken_frame.append(num_accum_frames + frame * 2)\n","#             except IndexError:\n","#               print(\"length of utterance: \",utterance.shape[0])\n","#               print(\"appended frame index:\",num_accum_frames + frame * 2)\n","#               pass\n","#             start = False\n","\n","#         for frame in range(orig_num_frames):\n","#             try:\n","#               taken_frame_orig.append(num_accum_frames_orig + frame)\n","#             except IndexError:\n","#               print(\"length of utterance: \",utterance.shape[0])\n","#               print(\"appended frame index:\",num_accum_frames + frame)\n","\n","#         num_accum_frames += number_of_frames * 2 + counter\n","#         num_accum_frames_orig += orig_num_frames\n","#     print(taken_frame)\n","#     print(taken_frame_orig)\n","#     print(durations)\n","#     print(num_accum_frames)\n","#     print(num_accum_frames_orig)\n","#   list_phones_dicts.append(phones_dict)\n","#   # break\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ph7CPeHo8Fxx"},"outputs":[],"source":["spk_dict_list = list_phones_dicts"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A-cjzIp48Jdl"},"outputs":[],"source":["phones, spk, joint = Averaging(spk_dict_list)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OL-9NM9zGCz_"},"outputs":[],"source":["joint_arrays, for_all, speaker_length = StackArrs(dir_list, joint)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XV4X-B5qGxV9"},"outputs":[],"source":["# create and display phone matrix\n","\n","phone_matrix = pd.DataFrame([ph[1] for ph in phones])\n","phone_matrix.set_axis([ph[0] for ph in phones], axis='index', inplace=True)\n","\n","# phone_matrix"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HcaqxI4oG2ep"},"outputs":[],"source":["# display speaker matrix\n","\n","speaker_matrix = pd.DataFrame(spk)\n","speaker_matrix.set_axis([id for id in dir_list], axis='index', inplace=True) # set speakers as row labels\n","\n","# speaker_matrix # display"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"abOBxvNTG7e0"},"outputs":[],"source":["joint_matrix = pd.DataFrame(joint_arrays)\n","# could name the phones column before saving as well!\n","joint_matrix.set_axis([spk[ph] for spk in for_all for ph in range(len(spk))], axis='index', inplace=True) # set phones as row labels\n","#joint_matrix[\"SPEAKER\"] = speaker_length # adds to end\n","joint_matrix.insert(0, \"Speaker\", speaker_length, True)\n","\n","# joint_matrix # display"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qRgdMgL_Ex5q"},"outputs":[],"source":["# import os\n","# # dir_path = \"/content/drive/MyDrive/Grad project/models_hidden_states/Wav2Vec2/layers_avg/layer_\" + str(layer_num)\n","# dir_path = \"/content/drive/MyDrive/Grad project/PCA\"\n","# os.makedirs(dir_path, exist_ok=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GpUDVoz99VJi"},"outputs":[],"source":["# output_dir = \"/content/drive/MyDrive/Grad project/models_hidden_states/Wav2Vec2/layers_avg/layer_\" + str(layer_num)\n","# output_dir = \"/content/drive/MyDrive/Grad project/models_hidden_states/Hubert_outputs/train-clean-matrices\"\n","# output_dir = \"/content/drive/MyDrive/Grad project/spk_phone_joint_matrices/Oli_20ms_interval\"\n","output_dir = \"/content/drive/MyDrive/Grad project/spk_phone_joint_matrices/\" + model + \"/layer_\" + str(layer_num)\n","os.makedirs(output_dir, exist_ok=True)\n","# output_dir = \"/content/drive/MyDrive/Grad project/spk_phone_joint_matrices/Hubert/conv_layer\"\n","# save joint matrix as .csv file from panda df\n","\n","joint_matrix.to_csv(output_dir + \"/joint_matrix.csv\", encoding = 'utf-8-sig')\n","\n","# save phone matrix as .npy file\n","\n","phone_matrix.to_csv(output_dir + \"/phone_matrix.csv\", encoding = 'utf-8-sig')\n","\n","# save speaker matrix .npy file\n","\n","speaker_matrix.to_csv(output_dir + '/speaker_matrix.csv', encoding = 'utf-8-sig')\n","np.save(output_dir +'/speaker_matrix.npy', spk)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-knczKihP2YH"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[],"mount_file_id":"1WB_3iA1ztvlo6nPMT5bLeDpo8D4AU6Un","authorship_tag":"ABX9TyPePBlDAxq1BpLEe8evGhNf"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}